{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMO38G+ffhwAL3G+RSWOTum",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "ir",
      "display_name": "R"
    },
    "language_info": {
      "name": "R"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GRARLBD/FIA2023-TPI/blob/main/FIA2023_TPI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "5nZAg-HIeAnr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee28d34c-ee7b-4275-e986-723a79c64bac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Installing package into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n",
            "\n",
            "Installing package into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n",
            "\n",
            "Installing package into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n",
            "\n",
            "also installing the dependencies ‘distributional’, ‘numDeriv’, ‘quadprog’, ‘Rcpp’\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "install.packages('lubridate')\n",
        "install.packages('ggplot2')\n",
        "install.packages('ggdist')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "install.packages('neuralnet')\n",
        "install.packages('NeuralNetTools')\n",
        "install.packages('gridExtra')\n"
      ],
      "metadata": {
        "id": "a7SLVVP3ftuO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "install.packages(\"e1071\")#svm\n",
        "install.packages(\"randomForest\") #randomForest\n",
        "install.packages(\"clock\") #necesaria para instalar 'caret'\n",
        "install.packages(\"caret\") #para el particionado del df\n",
        "install.packages(\"fastDummies\") #para realizar el casteo (one-hot encoding)"
      ],
      "metadata": {
        "id": "A83gumzMxzZs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "library(lubridate)\n",
        "library(ggplot2)\n",
        "library(ggdist)\n",
        "library(dplyr)\n",
        "library('neuralnet')\n",
        "library('NeuralNetTools')\n",
        "library('gridExtra')\n",
        "library(e1071)\n",
        "library(randomForest)\n",
        "library(dplyr)\n",
        "library(caret)\n",
        "library(reshape2)\n",
        "library(fastDummies)"
      ],
      "metadata": {
        "id": "MVmeQU2jercM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_princess<- read.csv(\"/content/princess.csv\")\n",
        "df_wine <- read.csv(\"/content/wine.csv\")"
      ],
      "metadata": {
        "id": "_UvfcTqcfEPV"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "table(df_princess$Cured)"
      ],
      "metadata": {
        "id": "eHfdCnm-0g_A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "head(df_wine) # MOSTRAMOS LA PRIMERAS FILAS\n"
      ],
      "metadata": {
        "id": "Wo9YRWIBU7ja"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mostrar resumen estadístico\n",
        "summary(df_wine)\n"
      ],
      "metadata": {
        "id": "MDHg8Sl_Flyq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summary(df_princess)"
      ],
      "metadata": {
        "id": "YfcYMtGIlZcP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "str(df_princess) # muestra la estructura del dataset"
      ],
      "metadata": {
        "id": "07Pi0274EKy5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cat(\"Nro de filas 'DF_WINE' : \", nrow(df_wine)) # muestra el número de filas en el data frame\n",
        "# Vemos si hay campos nulos en alguna columna\n",
        "cat(\"\\nDatos nulos en cada columna: ' : \", colSums(is.na(df_wine)), \"\\n\")\n",
        "\n",
        "# Obtener índices de las filas duplicadas\n",
        "indices_duplicados <- which(duplicated(df_wine) | duplicated(df_wine, fromLast = TRUE))\n",
        "\n",
        "if (length(indices_duplicados) > 0) {\n",
        "  print(paste(\"El conjunto de datos tiene\", length(indices_duplicados), \"filas duplicadas.\"))\n",
        "  # Mostrar los índices de las filas duplicadas\n",
        "  print(\"Índices de filas duplicadas:\")\n",
        "  print(indices_duplicados)\n",
        "  # Mostrar las filas duplicadas\n",
        "  print(\"Filas duplicadas:\")\n",
        "  print(df_wine[indices_duplicados, ])\n",
        "} else {\n",
        "  print(\"No se encontraron filas duplicadas en el conjunto de datos.\")\n",
        "}\n"
      ],
      "metadata": {
        "id": "exB3QNuFFgUp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Eliminar filas duplicadas del conjunto de datos 'datos'\n",
        "datos_sin_duplicados <- unique(df_wine)\n",
        "\n",
        "# Mostrar la cantidad de filas antes y después de eliminar duplicados\n",
        "print(paste(\"Número de filas antes de eliminar duplicados:\", nrow(df_wine)))\n",
        "print(paste(\"Número de filas después de eliminar duplicados:\", nrow(datos_sin_duplicados)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qpEyFeyzT7Vs",
        "outputId": "a3da9d8b-493d-4df9-b05b-c4006a476e6b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1] \"Número de filas antes de eliminar duplicados: 1599\"\n",
            "[1] \"Número de filas después de eliminar duplicados: 1359\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cat(\"Distribución de los valores de la etiqueta\\n\")\n",
        "table(datos_sin_duplicados$quality)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "id": "f9wwNwalUxh2",
        "outputId": "f055ee8a-c1aa-4492-abb0-a3ec6badb79a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distribución de los valores de la etiqueta\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              " bad good \n",
              " 640  719 "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Filtrar el conjunto de datos por etiquetas \"good\" y \"bad\"\n",
        "datos_good <- subset(datos_sin_duplicados, datos_sin_duplicados$quality == \"good\")\n",
        "datos_bad <- subset(datos_sin_duplicados, datos_sin_duplicados$quality == \"bad\")\n",
        "\n",
        "# Seleccionar aleatoriamente 640 registros de cada etiqueta\n",
        "datos_good_seleccionados <- datos_good[sample(nrow(datos_good), 640, replace = FALSE), ]\n",
        "datos_bad_seleccionados <- datos_bad[sample(nrow(datos_bad), 640, replace = FALSE), ]\n",
        "\n",
        "# Combinar los datos seleccionados de cada etiqueta en un nuevo conjunto de datos equilibrado\n",
        "datos_equilibrados <- rbind(datos_good_seleccionados, datos_bad_seleccionados)\n",
        "\n",
        "# Verificar la cantidad de filas por etiqueta en el conjunto de datos final\n",
        "cat(\"DATASET EQUILIBRADO : \\n\")\n",
        "print(table(datos_equilibrados$quality))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "crh1xd1IWfaZ",
        "outputId": "bf78f2cd-92c8-4f8d-bfab-fff7e905c121"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DATASET EQUILIBRADO : \n",
            "\n",
            " bad good \n",
            " 640  640 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#PREDICION CON SVM\n",
        "\n",
        "df_balanceado160SVM = datos_equilibrados\n",
        "df_balanceado160SVM$quality <- as.factor(df_balanceado160SVM$quality)\n",
        "\n",
        "# Función para normalización Min-Max\n",
        "normalize_min_max <- function(x) {\n",
        "  return((x - min(x)) / (max(x) - min(x)))\n",
        "}\n",
        "\n",
        "# Seleccionar solo las columnas numéricas para la normalización\n",
        "columnas_numericas <- sapply(df_balanceado160SVM, is.numeric)\n",
        "df_balanceado160SVM[columnas_numericas] <- lapply(df_balanceado160SVM[columnas_numericas], normalize_min_max)\n",
        "\n",
        "# Inicializar un vector para almacenar las precisiones de cada iteración\n",
        "precisiones <- numeric(100)\n",
        "\n",
        "# Iterar 100 veces\n",
        "for (i in 1:100) {\n",
        "    # Código para particionar el conjunto de datos, entrenar y evaluar el modelo SVM\n",
        "    set.seed(2023 + i) # Cambiar la semilla para cada iteración\n",
        "    t.ids <- createDataPartition(df_balanceado160SVM$quality, p = 0.7, list = FALSE)\n",
        "    modelo <- svm(quality ~ ., data = df_balanceado160SVM[t.ids, ], kernel = \"radial\")\n",
        "    prediccion <- predict(modelo, df_balanceado160SVM[-t.ids, ])\n",
        "    matriz_confusion <- table(df_balanceado160SVM$quality[-t.ids], prediccion, dnn = c('Real', 'Predicho'))\n",
        "    confusion_matrix <- confusionMatrix(matriz_confusion)\n",
        "    precisiones[i] <- confusion_matrix$overall['Accuracy']\n",
        "}\n",
        "\n",
        "# Mostrar la precisión promedio y otros detalles\n",
        "cat(\"Precisión promedio (Accuracy):\", mean(precisiones), \"\\n\")\n",
        "cat(\"Desviación estándar de la precisión:\", sd(precisiones), \"\\n\")\n",
        "cat(\"\\n{***** Detalles del entrenamiento del modelo SVM *****}\\n\\n\")\n",
        "\n",
        "confusion_matrix"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 608
        },
        "id": "eW6wyQNJY_w6",
        "outputId": "3a971877-c28b-434c-91e5-812174615e2d"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precisión promedio (Accuracy): 0.7470573 \n",
            "Desviación estándar de la precisión: 0.01877036 \n",
            "\n",
            "{***** Detalles del entrenamiento del modelo SVM *****}\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Confusion Matrix and Statistics\n",
              "\n",
              "      Predicho\n",
              "Real   bad good\n",
              "  bad  152   40\n",
              "  good  61  131\n",
              "                                          \n",
              "               Accuracy : 0.737           \n",
              "                 95% CI : (0.6899, 0.7803)\n",
              "    No Information Rate : 0.5547          \n",
              "    P-Value [Acc > NIR] : 1.223e-13       \n",
              "                                          \n",
              "                  Kappa : 0.474           \n",
              "                                          \n",
              " Mcnemar's Test P-Value : 0.04658         \n",
              "                                          \n",
              "            Sensitivity : 0.7136          \n",
              "            Specificity : 0.7661          \n",
              "         Pos Pred Value : 0.7917          \n",
              "         Neg Pred Value : 0.6823          \n",
              "             Prevalence : 0.5547          \n",
              "         Detection Rate : 0.3958          \n",
              "   Detection Prevalence : 0.5000          \n",
              "      Balanced Accuracy : 0.7398          \n",
              "                                          \n",
              "       'Positive' Class : bad             \n",
              "                                          "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#PREDICION CON RANDOM FOREST\n",
        "\n",
        "df_rf= datos_equilibrados\n",
        "df_rf$quality <- as.factor(df_rf$quality)\n",
        "\n",
        "# Función para normalización Min-Max\n",
        "normalize_min_max <- function(x) {\n",
        "  return((x - min(x)) / (max(x) - min(x)))\n",
        "}\n",
        "\n",
        "# Seleccionar solo las columnas numéricas para la normalización\n",
        "columnas_numericas <- sapply(df_rf, is.numeric)\n",
        "df_rf[columnas_numericas] <- lapply(df_rf[columnas_numericas], normalize_min_max)\n",
        "\n",
        "# Inicializar un vector para almacenar las precisiones de cada iteración\n",
        "precisiones_rf <- numeric(100)\n",
        "\n",
        "# Iterar 100 veces\n",
        "for (i in 1:100) {\n",
        "  # Establecer semilla para reproducibilidad en cada iteración\n",
        "  set.seed(2023 + i)\n",
        "\n",
        "  # Crear índices para dividir el conjunto de datos en entrenamiento (70%) y prueba (30%)\n",
        "  t.ids <- sample(nrow(df_rf), 0.7 * nrow(df_rf))\n",
        "  test.ids <- setdiff(1:nrow(df_rf), t.ids)\n",
        "  modelo_rf <- randomForest(quality ~ ., data = df_rf[t.ids, ])\n",
        "\n",
        "  prediccion_rf <- predict(modelo_rf, newdata = df_rf[test.ids, ])\n",
        "  matriz_confusion <- table(prediccion_rf, df_rf$quality[test.ids], dnn = c('Real' ,'Predicho'))\n",
        "  confusion_matrix <- confusionMatrix(matriz_confusion)\n",
        "  precisiones_rf[i] <- confusion_matrix$overall['Accuracy']\n",
        "}\n",
        "\n",
        "# Mostrar la precisión promedio y otros detalles\n",
        "cat(\"Precisión promedio (Accuracy) del modelo de Random Forest:\", mean(precisiones_rf), \"\\n\")\n",
        "cat(\"Desviación estándar de la precisión:\", sd(precisiones_rf), \"\\n\")\n",
        "cat(\"\\n{***** Detalles del entrenamiento del modelo de Random Forest *****}\\n\\n\")\n",
        "\n",
        "confusion_matrix\n"
      ],
      "metadata": {
        "id": "wFxhQK7Cu-i3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 608
        },
        "outputId": "b2f3023f-634f-4192-a2de-a828b9debd73"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precisión promedio (Accuracy) del modelo de Random Forest: 0.763724 \n",
            "Desviación estándar de la precisión: 0.01997336 \n",
            "\n",
            "{***** Detalles del entrenamiento del modelo de Random Forest *****}\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Confusion Matrix and Statistics\n",
              "\n",
              "      Predicho\n",
              "Real   bad good\n",
              "  bad  144   48\n",
              "  good  52  140\n",
              "                                          \n",
              "               Accuracy : 0.7396          \n",
              "                 95% CI : (0.6926, 0.7828)\n",
              "    No Information Rate : 0.5104          \n",
              "    P-Value [Acc > NIR] : <2e-16          \n",
              "                                          \n",
              "                  Kappa : 0.4792          \n",
              "                                          \n",
              " Mcnemar's Test P-Value : 0.7642          \n",
              "                                          \n",
              "            Sensitivity : 0.7347          \n",
              "            Specificity : 0.7447          \n",
              "         Pos Pred Value : 0.7500          \n",
              "         Neg Pred Value : 0.7292          \n",
              "             Prevalence : 0.5104          \n",
              "         Detection Rate : 0.3750          \n",
              "   Detection Prevalence : 0.5000          \n",
              "      Balanced Accuracy : 0.7397          \n",
              "                                          \n",
              "       'Positive' Class : bad             \n",
              "                                          "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rm(list = ls())\n"
      ],
      "metadata": {
        "id": "_42qwrcxJ3uq"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#PREDICION CON REDES NEURONALES\n",
        "\n",
        "# Crear una copia de 'datos_equilibrados' con solo las columnas deseadas\n",
        "df_redes_neuronales <- datos_equilibrados\n",
        "\n",
        "# Convertir 'quality' a valores numéricos (por ejemplo, 'good' a 1 y 'bad' a 0)\n",
        "df_redes_neuronales$quality <- ifelse(df_redes_neuronales$quality == \"good\", 1, 0)\n",
        "\n",
        "# Función para normalización Min-Max\n",
        "normalize_min_max <- function(x) {\n",
        "  return((x - min(x)) / (max(x) - min(x)))\n",
        "}\n",
        "\n",
        "# Seleccionar solo las columnas numéricas para la normalización\n",
        "columnas_numericas <- sapply(df_redes_neuronales, is.numeric)\n",
        "df_redes_neuronales[columnas_numericas] <- lapply(df_redes_neuronales[columnas_numericas], normalize_min_max)\n",
        "\n",
        "# Establecer semilla para reproducibilidad\n",
        "set.seed(123)\n",
        "\n",
        "# Número de filas en el conjunto de datos\n",
        "num_filas <- nrow(df_redes_neuronales)\n",
        "\n",
        "# Índices para conjunto de entrenamiento (70%) y prueba (30%)\n",
        "indice_entrenamiento <- sample(1:num_filas, 0.7 * num_filas, replace = FALSE)\n",
        "indice_prueba <- setdiff(1:num_filas, indice_entrenamiento)\n",
        "\n",
        "# Crear conjuntos de datos de entrenamiento y prueba\n",
        "datos_entrenamiento <- df_redes_neuronales[indice_entrenamiento, ]\n",
        "datos_prueba <- df_redes_neuronales[indice_prueba, ]\n",
        "\n",
        "\n",
        "red <- neuralnet(\n",
        "  quality ~ ., # Fórmula (ajusta a tus nombres de columnas)\n",
        "  data = datos_entrenamiento, # Conjunto de datos\n",
        "  hidden=10, #capas ocultas\n",
        "  linear.output = FALSE, #si act.fct NO debe aplicarse a la salida, TRUE, de lo contrario como FALSE.\n",
        "  act.fct=\"logistic\", #función de activación\n",
        "  algorithm=\"backprop\", #tipo de algoritmo\n",
        "  threshold=0.2, #umbral\n",
        "  learningrate=0.005, #tasa de aprendizaje\n",
        "  rep=100 #cantidad de repeticiones\n",
        ")\n",
        "\n",
        "# Calcular las salidas de la red neuronal para los datos de prueba\n",
        "resultados <- compute(red, datos_prueba[, -ncol(datos_prueba)])"
      ],
      "metadata": {
        "id": "lSypEAguflbv"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtener las predicciones para los datos de prueba\n",
        "predicciones <- ifelse(resultados$net.result > 0.5, 1, 0)\n",
        "\n",
        "# Calcular la precisión manualmente\n",
        "precision <- sum(predicciones == datos_prueba$quality) / length(predicciones)\n",
        "\n",
        "# Mostrar la precisión\n",
        "cat(\"Precisión en datos de prueba:\", precision, \"\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "asw37h1uwJuQ",
        "outputId": "7c3a445f-9295-42be-a516-a8c02a4f756b"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precisión en datos de prueba: 0.7213542 \n"
          ]
        }
      ]
    }
  ]
}